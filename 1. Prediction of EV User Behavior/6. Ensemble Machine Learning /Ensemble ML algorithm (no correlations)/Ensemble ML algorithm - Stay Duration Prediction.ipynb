{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15409,"status":"ok","timestamp":1700701754954,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"DL0k10RoUPJW","outputId":"f43632b1-ca91-4f69-ad5e-6ae26edbf4ab"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1776,"status":"ok","timestamp":1700701758953,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"M1Ot-FcdUzts"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","# Define the file paths\n","file_path1 = '/content/drive/MyDrive/SuperUROP /Data Analysis/caltech_training_data.csv'\n","file_path2 = '/content/drive/MyDrive/SuperUROP /Data Analysis/caltech_testing_data.csv'\n","file_path3 = '/content/drive/MyDrive/SuperUROP /Data Analysis/JPL_training_data.csv'\n","file_path4  = '/content/drive/MyDrive/SuperUROP /Data Analysis/JPL_testing_data.csv'\n","# Use pandas to read the CSV files and then convert them to NumPy arrays\n","caltech_train = pd.read_csv(file_path1).values\n","caltech_test = pd.read_csv(file_path2).values\n","\n","JPL_train = pd.read_csv(file_path3).values\n","JPL_test=pd.read_csv(file_path4).values"]},{"cell_type":"markdown","metadata":{"id":"T-LH42jEdjoD"},"source":["#Data Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1700701758954,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"WbbS_zZRVPX4"},"outputs":[],"source":["#Remove row number (in 1st column)\n","caltech_train=caltech_train[:,1:]\n","caltech_test=caltech_test[:,1:]\n","\n","JPL_train=JPL_train[:,1:]\n","JPL_test=JPL_test[:,1:]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":139,"status":"ok","timestamp":1700701762784,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"8P5wsz9EVgXL"},"outputs":[],"source":["#Remove departure time (2nd column)\n","# Convert arrival date to hour and find day of the week\n","from datetime import datetime\n","\n","def convert_time_and_day(data_array):\n","    \"\"\"\n","    Converts the time from HH:MM to HH.XX format and appends the day of the week to it.\n","    Also, removes the second column.\n","    \"\"\"\n","    transformed_data = []\n","    for row in data_array:\n","        # Convert the arrival time to HH.XX format\n","        time_obj = datetime.strptime(row[0], '%Y-%m-%d %H:%M:%S')\n","        new_time = time_obj.hour + (time_obj.minute / 60.0)\n","\n","        # Convert the date to a day of the week\n","        day_of_week = time_obj.strftime('%A')\n","        new_time = str(new_time) + \" \" + day_of_week\n","\n","        # Create a new row excluding the second column\n","        new_row = [new_time] + list(row[2:])\n","        transformed_data.append(new_row)\n","\n","    return np.array(transformed_data)\n","\n","caltech_train=convert_time_and_day(caltech_train)\n","caltech_test=convert_time_and_day(caltech_test)\n","JPL_train=convert_time_and_day(JPL_train)\n","JPL_test=convert_time_and_day(JPL_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":138,"status":"ok","timestamp":1700701764308,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"KFJTpBVqd-jm"},"outputs":[],"source":["def day_to_number(day):\n","    \"\"\"Converts a day of the week to its corresponding discrete value.\"\"\"\n","    days = {\n","        'Monday': 1,\n","        'Tuesday': 2,\n","        'Wednesday': 3,\n","        'Thursday': 4,\n","        'Friday': 5,\n","        'Saturday': 6,\n","        'Sunday': 7\n","    }\n","    return days[day]\n","\n","def separate_time_and_day(data_array):\n","    \"\"\"\n","    Separates the time and day in the given column,\n","    and converts the day into a discrete value between 1 and 7.\n","\n","    \"\"\"\n","    transformed_data = []\n","    for row in data_array:\n","        time_day_str = row[0]\n","        time, day = time_day_str.split()\n","        time = float(time)\n","        day_num = day_to_number(day)\n","\n","        # Create a new row with separated time and day number\n","        new_row = [time, day_num] + list(row[1:])\n","        transformed_data.append(new_row)\n","\n","    return np.array(transformed_data)\n","\n","caltech_train=separate_time_and_day(caltech_train)\n","caltech_test=separate_time_and_day(caltech_test)\n","JPL_train=separate_time_and_day(JPL_train)\n","JPL_test=separate_time_and_day(JPL_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":122,"status":"ok","timestamp":1700701765866,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"OYcBnwTisZ8n"},"outputs":[],"source":["#Make training and testing set have the same user IDs\n","users_from_training_caltech = set(caltech_train[:, 3])\n","mask_caltech = np.isin(caltech_test[:, 3], list(users_from_training_caltech))\n","caltech_test = caltech_test[mask_caltech]\n","users_from_testing_caltech = set(caltech_test[:, 3])\n","mask_caltech = np.isin(caltech_train[:, 3], list(users_from_testing_caltech))\n","caltech_train = caltech_train[mask_caltech]\n","\n","users_from_training = set(JPL_train[:, 3])\n","mask = np.isin(JPL_test[:, 3], list(users_from_training))\n","JPL_test = JPL_test[mask]\n","users_from_testing = set(JPL_test[:, 3])\n","mask = np.isin(JPL_train[:, 3], list(users_from_testing))\n","JPL_train = JPL_train[mask]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":341,"status":"ok","timestamp":1700701767374,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"eORUVi8wemPe"},"outputs":[],"source":["caltech_train = np.array(caltech_train, dtype='float')\n","caltech_test = np.array(caltech_test, dtype='float')\n","JPL_train = np.array(JPL_train, dtype='float')\n","JPL_test = np.array(JPL_test, dtype='float')"]},{"cell_type":"markdown","metadata":{"id":"_lb8SBPyl3dm"},"source":["#MLR stay duration prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"15wlGHu9YPb_"},"outputs":[],"source":["import numpy as np\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","\n","# Sample training data\n","\n","def mlr_model(train_data, test_data, user_id):\n","\n","    # Filter training and testing data for the specific user\n","    user_train_data = train_data[train_data[:, 3] == user_id]\n","    user_test_data = test_data[test_data[:, 3] == user_id]\n","\n","    # Independent variables are arrival time and day of the week\n","    X_train = user_train_data[:, :2]\n","    X_test = user_test_data[:, :2]\n","\n","    # Dependent variable is the duration\n","    y_train = user_train_data[:, 4]\n","    y_test = user_test_data[:, 4]\n","\n","    # Train the model\n","    model = LinearRegression().fit(X_train, y_train)\n","\n","    # Predict on the test set\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate user SMAPE\n","    n = len(y_test)\n","    smape_val = (1/ n) * np.sum(np.abs(y_test - y_pred) / (np.abs(y_test+y_pred)))*100\n","\n","    return model, smape_val\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":187,"status":"ok","timestamp":1700618473377,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"998SjZLkizHh","outputId":"da92083c-4587-4a89-bfd2-03d40b86dd0a"},"outputs":[],"source":["# Test the function\n","user_ids_JPL = np.unique(np.concatenate((JPL_train[:, 3], JPL_test[:, 3])))\n","smape_list_JPL=[]\n","\n","for user_id in user_ids_JPL:\n","    model, smape = mlr_model(JPL_train, JPL_test, user_id)\n","    smape_list_JPL.append(smape)\n","\n","#Calculate average SMAPE for JPL\n","no_JPL_users=len(user_ids_JPL)\n","JPL_smape=sum(smape_list_JPL)/no_JPL_users\n","print(f\"Average SMAPE for JPL dataset using MLR: {JPL_smape}\")"]},{"cell_type":"markdown","metadata":{"id":"PUfBsDhBcNj7"},"source":["#Mode stay duration prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":203,"status":"ok","timestamp":1700701772475,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"9uFkhXilcrSQ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","# Define the file paths\n","file_path1 = '/content/drive/MyDrive/SuperUROP /Data Analysis/caltech_training_data.csv'\n","file_path2 = '/content/drive/MyDrive/SuperUROP /Data Analysis/caltech_testing_data.csv'\n","file_path3 = '/content/drive/MyDrive/SuperUROP /Data Analysis/JPL_training_data.csv'\n","file_path4  = '/content/drive/MyDrive/SuperUROP /Data Analysis/JPL_testing_data.csv'\n","# Use pandas to read the CSV files and then convert them to NumPy arrays\n","Caltech_data_training = pd.read_csv(file_path1).values\n","Caltech_data_testing = pd.read_csv(file_path2).values\n","\n","JPL_training_data = pd.read_csv(file_path3).values\n","JPL_testing_data=pd.read_csv(file_path4).values"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":121,"status":"ok","timestamp":1700701773917,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"7AWuxE85giNG"},"outputs":[],"source":["Caltech_data_training=Caltech_data_training[:,1:]\n","Caltech_data_testing=Caltech_data_testing[:,1:]\n","\n","JPL_training_data=JPL_training_data[:,1:]\n","JPL_testing_data=JPL_testing_data[:,1:]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1700701774411,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"cjVXPdEwglA1"},"outputs":[],"source":["sorted_caltech_training = sorted(Caltech_data_training, key=lambda x: x[3])\n","sorted_caltech_training=np.delete(sorted_caltech_training, [1], axis=1)\n","sorted_caltech_testing = sorted(Caltech_data_testing, key=lambda x: x[3])\n","sorted_caltech_testing=np.delete(sorted_caltech_testing, [1], axis=1)\n","\n","\n","sorted_JPL_training = sorted(JPL_training_data, key=lambda x: x[3])\n","sorted_JPL_training=np.delete(sorted_JPL_training, [1], axis=1)\n","sorted_JPL_testing = sorted(JPL_testing_data, key=lambda x: x[3])\n","sorted_JPL_testing=np.delete(sorted_JPL_testing, [1], axis=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":154,"status":"ok","timestamp":1700701775474,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"FNblM1zBgn9s"},"outputs":[],"source":["def convert_to_interval(datetime_str):\n","    # Extract time string from the datetime string\n","    time_str = datetime_str.split()[1]\n","\n","    # Convert time string into hours, minutes, and seconds\n","    hours, minutes, seconds = map(int, time_str.split(':'))\n","\n","    # Calculate total minutes\n","    total_minutes = hours * 60 + minutes\n","\n","    # Find the nearest lower multiple of 15 for the minutes\n","    interval_minutes = (total_minutes // 15) * 15\n","\n","    # Convert back to hour and minute\n","    interval_hour, interval_minute = divmod(interval_minutes, 60)\n","\n","    # Return as a formatted string\n","    return \"{:02d}:{:02d}\".format(interval_hour, interval_minute)\n","\n","# Apply the conversion to the data\n","sorted_caltech_training[:, 0] = np.vectorize(convert_to_interval)(sorted_caltech_training[:, 0])\n","sorted_caltech_testing[:, 0] = np.vectorize(convert_to_interval)(sorted_caltech_testing[:, 0])\n","\n","sorted_JPL_training[:, 0] = np.vectorize(convert_to_interval)(sorted_JPL_training[:, 0])\n","sorted_JPL_testing[:, 0] = np.vectorize(convert_to_interval)(sorted_JPL_testing[:, 0])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":153,"status":"ok","timestamp":1700701777319,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"aSMi35DTgp4A"},"outputs":[],"source":["sorted_caltech_training[:, 3] = sorted_caltech_training[:, 3].astype(float) * 60\n","sorted_caltech_training[:, 3] = np.round(sorted_caltech_training[:, 3].astype(float) / 10) * 10\n","sorted_caltech_testing[:, 3] = sorted_caltech_testing[:, 3].astype(float) * 60\n","sorted_caltech_testing[:, 3] = np.round(sorted_caltech_testing[:, 3].astype(float) / 10) * 10\n","\n","sorted_JPL_training[:, 3] = sorted_JPL_training[:, 3].astype(float) * 60\n","sorted_JPL_training[:, 3] = np.round(sorted_JPL_training[:, 3].astype(float) / 10) * 10\n","sorted_JPL_testing[:, 3] = sorted_JPL_testing[:, 3].astype(float) * 60\n","sorted_JPL_testing[:, 3] = np.round(sorted_JPL_testing[:, 3].astype(float) / 10) * 10"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700701778306,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"fOW57xGrgrmf"},"outputs":[],"source":["#Make training and testing set have the same user IDs\n","users_from_training_caltech = set(sorted_caltech_training[:, 2])\n","mask_caltech = np.isin(sorted_caltech_testing[:, 2], list(users_from_training_caltech))\n","sorted_caltech_testing = sorted_caltech_testing[mask_caltech]\n","users_from_testing_caltech = set(sorted_caltech_testing[:, 2])\n","mask_caltech = np.isin(sorted_caltech_training[:, 2], list(users_from_testing_caltech))\n","sorted_caltech_training = sorted_caltech_training[mask_caltech]\n","\n","users_from_training = set(sorted_JPL_training[:, 2])\n","mask = np.isin(sorted_JPL_testing[:, 2], list(users_from_training))\n","sorted_JPL_testing = sorted_JPL_testing[mask]\n","\n","users_from_testing = set(sorted_JPL_testing[:, 2])\n","mask = np.isin(sorted_JPL_training[:, 2], list(users_from_testing))\n","sorted_JPL_training = sorted_JPL_training[mask]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":218,"status":"ok","timestamp":1700701780739,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"gm84S2e1gtfz"},"outputs":[],"source":["# Convert time strings to total minutes for sorting\n","total_minutes_caltech_training = np.array([int(time.split(':')[0])*60 + int(time.split(':')[1]) for time in sorted_caltech_training[:, 0]])\n","total_minutes_caltech_testing = np.array([int(time.split(':')[0])*60 + int(time.split(':')[1]) for time in sorted_caltech_testing[:, 0]])\n","\n","total_minutes_JPL_training = np.array([int(time.split(':')[0])*60 + int(time.split(':')[1]) for time in sorted_JPL_training[:, 0]])\n","total_minutes_JPL_testing = np.array([int(time.split(':')[0])*60 + int(time.split(':')[1]) for time in sorted_JPL_testing[:, 0]])\n","\n","# Argsort first by the 3rd column and then by total_minutes\n","indices_caltech_training = np.lexsort((total_minutes_caltech_training, sorted_caltech_training[:, 2].astype(int)))\n","indices_caltech_testing = np.lexsort((total_minutes_caltech_testing, sorted_caltech_testing[:, 2].astype(int)))\n","\n","indices_JPL_training = np.lexsort((total_minutes_JPL_training, sorted_JPL_training[:, 2].astype(int)))\n","indices_JPL_testing = np.lexsort((total_minutes_JPL_testing, sorted_JPL_testing[:, 2].astype(int)))\n","# Use the sorted indices to reorder the array\n","sorted_data_caltech_training = sorted_caltech_training[indices_caltech_training]\n","sorted_data_caltech_testing = sorted_caltech_testing[indices_caltech_testing]\n","\n","sorted_data_JPL_training = sorted_JPL_training[indices_JPL_training]\n","sorted_data_JPL_testing = sorted_JPL_testing[indices_JPL_testing]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":121,"status":"ok","timestamp":1700701782358,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"48tygNBlg2GT"},"outputs":[],"source":["#Mode calculation with linear interpolation\n","from collections import Counter\n","def compute_mode_per_user_per_interval(data):\n","    \"\"\"Compute the mode per user per time interval with linear interpolation.\"\"\"\n","    user_groups = {}\n","    mode_per_user_per_interval = {}\n","\n","    # Group by user\n","    for row in data:\n","        if row[2] not in user_groups:\n","            user_groups[row[2]] = []\n","        user_groups[row[2]].append(row)\n","\n","    # Calculate modes per user\n","    for user, entries in user_groups.items():\n","        time_intervals = sorted(list(set([entry[0] for entry in entries])))\n","        modes = {}\n","        for interval in time_intervals:\n","            session_values = [entry[3] for entry in entries if entry[0] == interval]\n","            counts = Counter(session_values)\n","            highest_freq = max(counts.values())\n","            common_vals = [key for key, val in counts.items() if val == highest_freq]\n","\n","            # If there's a single mode, use it; else, average them\n","            modes[interval] = sum(common_vals) / len(common_vals)\n","\n","        # Linearly interpolate for missing modes\n","        all_intervals = sorted(list(set(data[:, 0])))\n","        for i, interval in enumerate(all_intervals):\n","            if interval not in modes:\n","                # Find previous and next known modes\n","                prev_mode = next((modes[prev_int] for prev_int in reversed(all_intervals[:i]) if prev_int in modes), None)\n","                next_mode = next((modes[next_int] for next_int in all_intervals[i+1:] if next_int in modes), None)\n","\n","                # If both previous and next modes exist, interpolate\n","                if prev_mode is not None and next_mode is not None:\n","                    gap_size = all_intervals[i+1:].index(next((next_int for next_int in all_intervals[i+1:] if next_int in modes))) + 1\n","                    increment = (next_mode - prev_mode) / (gap_size + 1)\n","                    modes[interval] = prev_mode + increment\n","\n","                # If no next mode exists, keep the mode same as the previous mode\n","                elif prev_mode is not None:\n","                    modes[interval] = prev_mode\n","\n","                # If no previous mode exists, keep the mode same as the next mode\n","                elif next_mode is not None:\n","                    modes[interval] = next_mode\n","\n","        mode_per_user_per_interval[user] = modes\n","\n","    return mode_per_user_per_interval\n","\n","# Update mode_per_user_per_interval using the new function\n","mode_per_user_per_interval_caltech_interpolate = compute_mode_per_user_per_interval(sorted_data_caltech_training)\n","mode_per_user_per_interval_JPL_interpolate = compute_mode_per_user_per_interval(sorted_data_JPL_training)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jCaxlJzcueAH"},"outputs":[],"source":["mode_per_user_per_interval_JPL_interpolate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BlxTQ7kZg9Xg"},"outputs":[],"source":["import numpy as np\n","\n","def calculate_smape_user_mode(y_true, y_pred):\n","    \"\"\"Compute the SMAPE\"\"\"\n","    n = len(y_true)\n","    if n == 0:\n","        return 0\n","    smape_val = (1 / n) * np.sum(np.abs(y_true - y_pred) / (np.abs(y_true + y_pred))) * 100\n","    return smape_val\n","\n","user_data = {}  # Dictionary to store per-user data\n","user_smape_mode = {}  # Dictionary to store per-user SMAPE\n","\n","for row in sorted_data_JPL_testing:\n","    user_id = row[2]  # Assuming user_id is at index 2\n","    time_slot = row[0]  # Assuming time_slot is at index 0\n","\n","    if row[0] in mode_per_user_per_interval_JPL_interpolate.get(row[2], {}):\n","        true_value = row[3]\n","        user_prediction=mode_per_user_per_interval_JPL_interpolate[row[2]][row[0]]\n","\n","        if user_id not in user_data:\n","            user_data[user_id] = {'y_true': [], 'y_pred': []}\n","\n","        user_data[user_id]['y_true'].append(true_value)\n","        user_data[user_id]['y_pred'].append(user_prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":168,"status":"ok","timestamp":1700618487927,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"5WWRaX9cjNXb","outputId":"79536621-3d6d-483c-dad6-ff5a261d257b"},"outputs":[],"source":["# Calculating SMAPE for each user\n","for user_id, data in user_data.items():\n","    y_true_user_mode = np.array(data['y_true'], dtype=float)\n","    y_pred_user_mode = np.array(data['y_pred'], dtype=float)\n","    smape = calculate_smape_user_mode(y_true_user_mode, y_pred_user_mode)\n","    user_smape_mode[user_id] = smape\n","\n","# Calculating the average SMAPE across all users\n","average_smape = np.mean(list(user_smape_mode.values())) if user_smape_mode else 0\n","print(f'Average SMAPE for JPL dataset using mode: {average_smape:.2f}%')"]},{"cell_type":"markdown","metadata":{"id":"SXXC3MSaCN94"},"source":["#Ensemble ML stay duration prediction (threshold of 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5IS-lA8WCiUf"},"outputs":[],"source":["R_SD={'169': 2.2551554266668488,\n"," '171': 3.7531759242694362,\n"," '176': 3.033506931058353,\n"," '220': 4.157056240805807,\n"," '322': 2.929926450352931,\n"," '334': 1.5403402896510696,\n"," '335': 4.182440356147159,\n"," '346': 4.63088280381524,\n"," '365': 4.612058546331858,\n"," '368': 3.8637314436567745,\n"," '372': 3.4779871035895753,\n"," '374': 3.7627475450103334,\n"," '378': 3.61759981491824,\n"," '382': 4.358454020839778,\n"," '404': 4.285879042160351,\n"," '405': 4.760574930778141,\n"," '406': 1.1510712960433436,\n"," '409': 3.3539069505133905,\n"," '410': 4.301005502712871,\n"," '416': 4.199233283013298,\n"," '436': 4.091891479434165,\n"," '444': 3.529125348909349,\n"," '458': 4.060001379997106,\n"," '467': 4.019928954004856,\n"," '474': 3.2450469879409285,\n"," '476': 4.393288833959378,\n"," '481': 4.429827240449028,\n"," '483': 3.079068807362642,\n"," '507': 4.336149365824373,\n"," '526': 2.4205249888839466,\n"," '531': 3.9517493146670986,\n"," '537': 3.1479021761196098,\n"," '551': 4.881572582872202,\n"," '553': 3.0305502893037675,\n"," '576': 3.628599820757222,\n"," '577': 4.319531561288392,\n"," '581': 3.4796093044547454,\n"," '592': 3.1009000797824084,\n"," '607': 4.831651402991986,\n"," '651': 3.6013651820057837,\n"," '726': 3.7379880870161575,\n"," '742': 4.150297519178871,\n"," '826': 3.710092899316145,\n"," '933': 4.41718644718856}\n","\n","R_SD = {int(key): value for key, value in R_SD.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143,"status":"ok","timestamp":1700618896609,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"DxqfMCDVhgcH","outputId":"3fb147f8-44d9-48e0-cc0f-bd9375328c4f"},"outputs":[],"source":["import numpy as np\n","\n","# Assuming R_DE, JPL_train, JPL_test, mlr_model, and dkde_model are already defined\n","\n","user_smape_combined = {}  # Dictionary to store SMAPE values for all users\n","\n","# Loop through each user ID in the JPL dataset\n","for user_id in user_ids_JPL:\n","    if R_SD.get(user_id, 0) > 3.7:\n","        # Use mlr_model for users with R_SD >3.7 (put 4 in the writing - with 4 get 10.71%)\n","        model, smape = mlr_model(JPL_train, JPL_test, user_id)\n","    else:\n","        smape=user_smape_mode.get(user_id, 0)\n","\n","    user_smape_combined[user_id] = smape  # Store the SMAPE in the dictionary\n","\n","# Calculate the overall average SMAPE for the entire dataset\n","average_smape_combined = np.mean(list(user_smape_combined.values()))\n","\n","print(f\"Average SMAPE for JPL dataset using ensemble approach with threshold of 4: {average_smape_combined:.2f}%\")\n"]},{"cell_type":"markdown","metadata":{"id":"bvi4NJ6zwWF_"},"source":["#Enseble ML stay duration prediction (threshold of 4.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":155,"status":"ok","timestamp":1700618900187,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"fO8s_hQ_wd_x","outputId":"1b109ae3-0b66-4eae-f892-ea87da13d4a1"},"outputs":[],"source":["import numpy as np\n","\n","# Assuming R_DE, JPL_train, JPL_test, mlr_model, and dkde_model are already defined\n","\n","user_smape_combined = {}  # Dictionary to store SMAPE values for all users\n","\n","# Loop through each user ID in the JPL dataset\n","for user_id in user_ids_JPL:\n","    if R_SD.get(user_id, 0) < 4.5:\n","        # Use mlr_model for users with R_SD >3.7 (put 4 in the writing - with 4 get 10.71%)\n","        model, smape = mlr_model(JPL_train, JPL_test, user_id)\n","    else:\n","        smape=user_smape_mode.get(user_id, 0)\n","\n","\n","    user_smape_combined[user_id] = smape  # Store the SMAPE in the dictionary\n","\n","# Calculate the overall average SMAPE for the entire dataset\n","average_smape_combined = np.mean(list(user_smape_combined.values()))\n","\n","print(f\"Average SMAPE for JPL dataset using ensemble approach with threshold of 4.5: {average_smape_combined:.2f}%\")\n"]},{"cell_type":"markdown","metadata":{"id":"Lm7rNyS8xdF9"},"source":["#Ensemble ML stay duration prediction (threshold of 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6318,"status":"ok","timestamp":1700618847837,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"OOilyyjgx_fD","outputId":"d0b0a0b2-c031-4617-bfa7-7897728cd8a8"},"outputs":[],"source":["! pip install KDE-diffusion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGJmcuo3xlEW"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","from kde_diffusion import kde2d\n","\n","def dkde_model(train_data,test_data,user_id):\n","    # Filter training and testing data for the specific user\n","    user_train_data = train_data[train_data[:, 3] == user_id]\n","    user_test_data = test_data[test_data[:, 3] == user_id]\n","\n","    # Extract columns for arrival time and stay duration for both train and test sets\n","    X_train = user_train_data[:, 0]  # Arrival time\n","    Y_train = user_train_data[:, 4] # Stay duration\n","\n","    X_test = user_test_data[:, 0]\n","    y_test = user_test_data[:, 4]\n","\n","    from kde_diffusion import kde2d\n","    (density, grid, bandwidth) = kde2d(X_train, Y_train, n=128, limits=None)\n","\n","    def predict_y_given_x(new_x, grid, density):\n","        # Find the closest x index\n","        x_idx = np.argmin(np.abs(grid[0] - new_x))\n","\n","        # Get the y values and their corresponding densities for the given x\n","        y_values = grid[1]\n","        y_densities = density[x_idx]\n","\n","        # Find the y with the maximum density\n","        predicted_y = y_values[np.argmax(y_densities)]\n","\n","        return predicted_y\n","\n","    # Predict y values for X_test using the density estimate\n","    y_pred = [predict_y_given_x(x_val, grid, density) for x_val in X_test]\n","\n","    # Calculate user SMAPE\n","    n = len(y_test)\n","    smape_val = (1/ n) * np.sum(np.abs(y_test - y_pred) / (np.abs(y_test+y_pred)))*100\n","\n","    return smape_val,density, grid\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5309,"status":"ok","timestamp":1700618879691,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"O4AC0x-uyJKN","outputId":"82290026-bb4d-4dc0-82d5-ab07d3b11ed9"},"outputs":[],"source":["# Initialize dictionaries to store user-wise SMAPE values\n","user_smape_JPL = {}\n","\n","# Loop through each user ID in the JPL dataset\n","for user_id in user_ids_JPL:\n","    smape, density, grid = dkde_model(JPL_train, JPL_test, user_id)\n","    user_smape_JPL[user_id] = smape  # Store the SMAPE in the dictionary\n","\n","average_smape_JPL = np.mean(list(user_smape_JPL.values()))\n","\n","print(f\"Average SMAPE for JPL dataset using DKDE: {average_smape_JPL:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":593,"status":"ok","timestamp":1700619000949,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"TXiR8tdzxlgf","outputId":"b7fbff0a-8d5f-4274-95e2-fd988b60a2ea"},"outputs":[],"source":["import numpy as np\n","\n","# Assuming R_DE, JPL_train, JPL_test, mlr_model, and dkde_model are already defined\n","\n","user_smape_combined = {}  # Dictionary to store SMAPE values for all users\n","\n","# Loop through each user ID in the JPL dataset\n","for user_id in user_ids_JPL:\n","    if R_SD.get(user_id, 0) < 3:\n","        # Use mlr_model for users with R_SD >3.7 (put 4 in the writing - with 4 get 10.71%)\n","        smape, density, grid = dkde_model(JPL_train, JPL_test, user_id)\n","    else:\n","        smape=user_smape_mode.get(user_id, 0)\n","\n","\n","    user_smape_combined[user_id] = smape  # Store the SMAPE in the dictionary\n","\n","# Calculate the overall average SMAPE for the entire dataset\n","average_smape_combined = np.mean(list(user_smape_combined.values()))\n","\n","print(f\"Average SMAPE for JPL dataset using ensemble approach with threshold of 3: {average_smape_combined:.2f}%\")\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOAPXKAeQHwKoj1ijqvs6WU","provenance":[{"file_id":"10AcxJ47kkB8LC7vBG7zF_iB5lvzI1OkP","timestamp":1700612828645},{"file_id":"1M7ugd_F2UMQ796HlUfsXUl_Ucqj4nf54","timestamp":1700605550468}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}

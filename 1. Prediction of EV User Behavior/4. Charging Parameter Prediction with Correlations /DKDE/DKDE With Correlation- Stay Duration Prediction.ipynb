{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15525,"status":"ok","timestamp":1700244845479,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"DL0k10RoUPJW","outputId":"9dc5f451-c5e8-4e10-c27c-c9407d91339f"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7215,"status":"ok","timestamp":1700244854629,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"yH2-I12ruMM7","outputId":"9683a67b-0643-46ab-b20c-cbeb2ae36c7d"},"outputs":[],"source":["! pip install KDE-diffusion"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":162,"status":"ok","timestamp":1700245230292,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"M1Ot-FcdUzts"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","# Define the file paths\n","file_path1 = '/content/drive/MyDrive/SuperUROP /Data Analysis/caltech_training_data.csv'\n","file_path2 = '/content/drive/MyDrive/SuperUROP /Data Analysis/caltech_testing_data.csv'\n","file_path3 = '/content/drive/MyDrive/SuperUROP /Data Analysis/JPL_training_data.csv'\n","file_path4  = '/content/drive/MyDrive/SuperUROP /Data Analysis/JPL_testing_data.csv'\n","# Use pandas to read the CSV files and then convert them to NumPy arrays\n","caltech_train = pd.read_csv(file_path1).values\n","caltech_test = pd.read_csv(file_path2).values\n","\n","JPL_train = pd.read_csv(file_path3).values\n","JPL_test=pd.read_csv(file_path4).values"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":148,"status":"ok","timestamp":1700246206343,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"_dNUl_88fRO2"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","# Define the file paths\n","file_path1 = '/content/drive/MyDrive/SuperUROP /Data Analysis/caltech_training_data.csv'\n","file_path2 = '/content/drive/MyDrive/SuperUROP /Data Analysis/caltech_testing_data.csv'\n","file_path3 = '/content/drive/MyDrive/SuperUROP /Data Analysis/JPL_training_data.csv'\n","file_path4 = '/content/drive/MyDrive/SuperUROP /Data Analysis/JPL_testing_data.csv'\n","\n","\n","\n","JPL_train_df = pd.read_csv(file_path3)\n","JPL_test_df = pd.read_csv(file_path4)\n","\n","file_path1 = '/content/drive/MyDrive/SuperUROP /Data Analysis/caltech_training_data.csv'\n","file_path2 = '/content/drive/MyDrive/SuperUROP /Data Analysis/caltech_testing_data.csv'\n","\n","JPL_train_df=JPL_train_df[JPL_train_df['no_sessions'] >= 30]\n","\n","# Convert to NumPy arrays if necessary\n","caltech_train = pd.read_csv(file_path1).values\n","caltech_test = pd.read_csv(file_path2).values #use original caltech files as don't converge otherwise\n","JPL_train = JPL_train_df.values\n","JPL_test = JPL_test_df.values\n"]},{"cell_type":"markdown","metadata":{"id":"T-LH42jEdjoD"},"source":["#Data Processing for DKDE\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":124,"status":"ok","timestamp":1700246209566,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"WbbS_zZRVPX4"},"outputs":[],"source":["#Remove row number (in 1st column)\n","caltech_train=caltech_train[:,1:]\n","caltech_test=caltech_test[:,1:]\n","\n","JPL_train=JPL_train[:,1:]\n","JPL_test=JPL_test[:,1:]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":120,"status":"ok","timestamp":1700246210132,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"8P5wsz9EVgXL"},"outputs":[],"source":["#Remove departure time (2nd column)\n","# Convert arrival date to hour and find day of the week\n","from datetime import datetime\n","\n","def convert_time_and_day(data_array):\n","    \"\"\"\n","    Converts the time from HH:MM to HH.XX format and appends the day of the week to it.\n","    Also, removes the second column.\n","    \"\"\"\n","    transformed_data = []\n","    for row in data_array:\n","        # Convert the arrival time to HH.XX format\n","        time_obj = datetime.strptime(row[0], '%Y-%m-%d %H:%M:%S')\n","        new_time = time_obj.hour + (time_obj.minute / 60.0)\n","\n","        # Convert the date to a day of the week\n","        day_of_week = time_obj.strftime('%A')\n","        new_time = str(new_time) + \" \" + day_of_week\n","\n","        # Create a new row excluding the second column\n","        new_row = [new_time] + list(row[2:])\n","        transformed_data.append(new_row)\n","\n","    return np.array(transformed_data)\n","\n","caltech_train=convert_time_and_day(caltech_train)\n","caltech_test=convert_time_and_day(caltech_test)\n","JPL_train=convert_time_and_day(JPL_train)\n","JPL_test=convert_time_and_day(JPL_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1700246211704,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"KFJTpBVqd-jm"},"outputs":[],"source":["def day_to_number(day):\n","    \"\"\"Converts a day of the week to its corresponding discrete value.\"\"\"\n","    days = {\n","        'Monday': 1,\n","        'Tuesday': 2,\n","        'Wednesday': 3,\n","        'Thursday': 4,\n","        'Friday': 5,\n","        'Saturday': 6,\n","        'Sunday': 7\n","    }\n","    return days[day]\n","\n","def separate_time_and_day(data_array):\n","    \"\"\"\n","    Separates the time and day in the given column,\n","    and converts the day into a discrete value between 1 and 7.\n","\n","    \"\"\"\n","    transformed_data = []\n","    for row in data_array:\n","        time_day_str = row[0]\n","        time, day = time_day_str.split()\n","        time = float(time)\n","        day_num = day_to_number(day)\n","\n","        # Create a new row with separated time and day number\n","        new_row = [time, day_num] + list(row[1:])\n","        transformed_data.append(new_row)\n","\n","    return np.array(transformed_data)\n","\n","caltech_train=separate_time_and_day(caltech_train)\n","caltech_test=separate_time_and_day(caltech_test)\n","JPL_train=separate_time_and_day(JPL_train)\n","JPL_test=separate_time_and_day(JPL_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":169,"status":"ok","timestamp":1700246212983,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"OYcBnwTisZ8n"},"outputs":[],"source":["#Make training and testing set have the same user IDs\n","users_from_training_caltech = set(caltech_train[:, 3])\n","mask_caltech = np.isin(caltech_test[:, 3], list(users_from_training_caltech))\n","caltech_test = caltech_test[mask_caltech]\n","users_from_testing_caltech = set(caltech_test[:, 3])\n","mask_caltech = np.isin(caltech_train[:, 3], list(users_from_testing_caltech))\n","caltech_train = caltech_train[mask_caltech]\n","\n","users_from_training = set(JPL_train[:, 3])\n","mask = np.isin(JPL_test[:, 3], list(users_from_training))\n","JPL_test = JPL_test[mask]\n","users_from_testing = set(JPL_test[:, 3])\n","mask = np.isin(JPL_train[:, 3], list(users_from_testing))\n","JPL_train = JPL_train[mask]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":129,"status":"ok","timestamp":1700246214794,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"eORUVi8wemPe"},"outputs":[],"source":["caltech_train = np.array(caltech_train, dtype='float')\n","caltech_test = np.array(caltech_test, dtype='float')\n","JPL_train = np.array(JPL_train, dtype='float')\n","JPL_test = np.array(JPL_test, dtype='float')"]},{"cell_type":"markdown","metadata":{"id":"yELKBYaHSvPO"},"source":["#Data processing for correllations (discretization)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":175,"status":"ok","timestamp":1700246215614,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"hBlAwEPNSyjh"},"outputs":[],"source":["from collections import defaultdict\n","\n","# Organize the arrival times by user ID for the entire dataset\n","user_times_cal = defaultdict(list)\n","user_times_JPL = defaultdict(list)\n","\n","# Accumulate all arrival times for each user in caltech_train\n","for row in caltech_train:\n","    arrival_time = float(row[0])\n","    user_id = row[3]\n","    user_times_cal[user_id].append(arrival_time)\n","\n","# Accumulate all arrival times for each user in JPL_train\n","for row in JPL_train:\n","    arrival_time = float(row[0])\n","    user_id = row[3]\n","    user_times_JPL[user_id].append(arrival_time)\n","\n","# Define the functions for hourly and half-hourly representations\n","def create_hourly_representation(times):\n","    hourly_vector = [0] * 24\n","    for time in times:\n","        hour = int(float(time))\n","        hourly_vector[hour] += 1\n","    return hourly_vector\n","\n","def create_half_hourly_representation(times):\n","    half_hourly_vector = [0] * 48\n","    for time in times:\n","        interval = int(float(time) * 2)  # Multiply by 2 for half-hourly intervals\n","        half_hourly_vector[interval] += 1\n","    return half_hourly_vector\n","\n","# Compute the hourly and half-hourly representations for each user\n","hourly_representations_cal = {}\n","half_hourly_representations_cal = {}\n","hourly_representations_JPL = {}\n","half_hourly_representations_JPL = {}\n","\n","for user_id, times in user_times_cal.items():\n","    hourly_representations_cal[user_id] = create_hourly_representation(times)\n","    half_hourly_representations_cal[user_id] = create_half_hourly_representation(times)\n","\n","for user_id, times in user_times_JPL.items():\n","    hourly_representations_JPL[user_id] = create_hourly_representation(times)\n","    half_hourly_representations_JPL[user_id] = create_half_hourly_representation(times)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":145,"status":"ok","timestamp":1700246217174,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"RbYqnzpoTJ7n"},"outputs":[],"source":["max_duration_caltech= int(np.round(caltech_train[:, 4].astype(float).max()))\n","max_duration_JPL= int(np.round(JPL_train[:, 4].astype(float).max()))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":202,"status":"ok","timestamp":1700246218062,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"ORxUMNMwTKb6"},"outputs":[],"source":["import numpy as np\n","from collections import defaultdict\n","\n","# Organize the energy consumption durations by user ID for the entire dataset\n","user_durations_cal = defaultdict(list)\n","user_durations_JPL = defaultdict(list)\n","\n","# Accumulate all energy consumption durations for each user in caltech_train\n","for row in caltech_train:\n","    stay_duration = float(row[4])\n","    user_id = row[3]\n","    user_durations_cal[user_id].append(stay_duration)\n","\n","# Accumulate all energy consumption durations for each user in JPL_train\n","for row in JPL_train:\n","    stay_duration = float(row[4])\n","    user_id = row[3]\n","    user_durations_JPL[user_id].append(stay_duration)\n","\n","# Define functions for hourly and half-hourly representations\n","def create_hourly_representation_duration(durations):\n","    hourly_vector = [0] * 24\n","    for duration in durations:\n","        index = int(float(duration))\n","        hourly_vector[index] += 1\n","    return hourly_vector\n","\n","def create_half_hourly_representation_duration(durations):\n","    half_hourly_vector = [0] * 48\n","    for duration in durations:\n","        interval = int(float(duration) * 2)\n","        half_hourly_vector[interval] += 1\n","    return half_hourly_vector\n","\n","# Compute the hourly and half-hourly representations for each user\n","hourly_representations_duration_cal = {}\n","half_hourly_representations_duration_cal = {}\n","hourly_representations_duration_JPL = {}\n","half_hourly_representations_duration_JPL = {}\n","\n","for user_id, durations in user_durations_cal.items():\n","    hourly_representations_duration_cal[user_id] = create_hourly_representation_duration(durations)\n","    half_hourly_representations_duration_cal[user_id] = create_half_hourly_representation_duration(durations)\n","\n","for user_id, durations in user_durations_JPL.items():\n","    hourly_representations_duration_JPL[user_id] = create_hourly_representation_duration(durations)\n","    half_hourly_representations_duration_JPL[user_id] = create_half_hourly_representation_duration(durations)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1700246220566,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"ea-OFUnwTpG-"},"outputs":[],"source":["def concatenate_representations(dict1, dict2):\n","    concatenated = {}\n","    for key in set(dict1.keys()) | set(dict2.keys()):  # union of keys from both dicts\n","        list1 = dict1.get(key, [])\n","        list2 = dict2.get(key, [])\n","\n","        # Concatenate the lists\n","        concatenated_list = list1 + list2\n","\n","        concatenated[key] = concatenated_list\n","\n","    return concatenated\n","\n","# Example usage\n","concatenated_hourly_cal = concatenate_representations(hourly_representations_cal, hourly_representations_duration_cal)\n","concatenated_half_hourly_cal = concatenate_representations(half_hourly_representations_cal, half_hourly_representations_duration_cal)\n","\n","concatenated_hourly_JPL = concatenate_representations(hourly_representations_JPL, hourly_representations_duration_JPL)\n","concatenated_half_hourly_JPL = concatenate_representations(half_hourly_representations_JPL, half_hourly_representations_duration_JPL)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"j6Ei18qKMM0P"},"source":["#Correlation calculation"]},{"cell_type":"markdown","metadata":{"id":"MpKvNIjFLwhJ"},"source":["##Cosine similarity calculation"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":136,"status":"ok","timestamp":1700246224288,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"tkQQql47Ultv"},"outputs":[],"source":["from sklearn.metrics import pairwise_distances\n","import pandas as pd\n","\n","def data_to_dataframe(data):\n","    return pd.DataFrame.from_dict(data, orient='index')\n","\n","def compute_cosine_similarity(df):\n","    cosine_distance = pairwise_distances(df, metric='cosine')\n","    cosine_similarity = 1 - cosine_distance\n","\n","    # Set the user IDs as row and column names to preserve them\n","    cosine_similarity_df = pd.DataFrame(cosine_similarity, index=df.index, columns=df.index)\n","    return cosine_similarity_df\n","\n","# Compute cosine similarity for each concatenated dataset\n","df_hourly_cal = data_to_dataframe(concatenated_hourly_cal)\n","similarities_hourly_cal = compute_cosine_similarity(df_hourly_cal)\n","\n","df_half_hourly_cal = data_to_dataframe(concatenated_half_hourly_cal)\n","similarities_half_hourly_cal = compute_cosine_similarity(df_half_hourly_cal)\n","\n","df_hourly_JPL = data_to_dataframe(concatenated_hourly_JPL)\n","similarities_hourly_JPL = compute_cosine_similarity(df_hourly_JPL)\n","\n","df_half_hourly_JPL = data_to_dataframe(concatenated_half_hourly_JPL)\n","similarities_half_hourly_JPL = compute_cosine_similarity(df_half_hourly_JPL)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"k3OsvvkML4p2"},"source":["##Pearson correlation calculation"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":165,"status":"ok","timestamp":1700245051627,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"_ZUpqfjarhtj"},"outputs":[],"source":["import numpy as np\n","\n","def compute_pearson_correlation(v1, v2):\n","    # Handling cases where vectors are too short or contain constant values\n","    if len(v1) > 1 and len(v2) > 1 and np.std(v1) * np.std(v2) != 0:\n","        return np.corrcoef(v1, v2)[0, 1]\n","    else:\n","        return None  # Returning None for cases where correlation is not defined\n","\n","import pandas as pd\n","\n","def compute_pearson_correlation_matrix_df(representations):\n","    user_ids = list(representations.keys())\n","    n = len(user_ids)\n","    correlation_matrix = np.zeros((n, n))\n","\n","    for i in range(n):\n","        for j in range(i, n):  # Compute only for one triangle and mirror it as the matrix is symmetric\n","            if i != j:\n","                corr = compute_pearson_correlation(representations[user_ids[i]], representations[user_ids[j]])\n","                correlation_matrix[i, j] = corr if corr is not None else 0\n","                correlation_matrix[j, i] = correlation_matrix[i, j]  # Mirror the value\n","            else:\n","                correlation_matrix[i, j] = 1  # Self-correlation is always 1\n","\n","    # Convert to DataFrame for better usability\n","    correlation_df = pd.DataFrame(correlation_matrix, index=user_ids, columns=user_ids)\n","    return correlation_df\n","\n","similarities_hourly_cal = compute_pearson_correlation_matrix_df(concatenated_hourly_cal)\n","similarities_half_hourly_cal = compute_pearson_correlation_matrix_df(concatenated_half_hourly_cal)\n","\n","similarities_hourly_JPL = compute_pearson_correlation_matrix_df(concatenated_hourly_JPL)\n","similarities_half_hourly_JPL = compute_pearson_correlation_matrix_df(concatenated_half_hourly_JPL)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ethVbrTjL9ta"},"source":["#Find most correlated users (using energy and raw values)\n","Raw threshold performs better (choose a threshold of 0.5/0.75 depending on the data)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":131,"status":"ok","timestamp":1700246129052,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"sjgEz85CgSCD"},"outputs":[],"source":["#Using energy\n","def most_correlated_users(matrix, threshold=0.5):\n","    \"\"\"\n","    For each user, calculate the top correlated users that cumulatively contribute to a given energy threshold.\n","\n","    :param matrix: Cosine similarity matrix.\n","    :param threshold: Energy threshold.\n","    :return: Dictionary with keys being user IDs and values being lists of top correlated user IDs.\n","    \"\"\"\n","    result = {}\n","\n","    for user_index in matrix.index:\n","        # Subtract self-similarity value for the current user\n","        user_similarities = matrix.loc[user_index].drop(user_index)\n","\n","        # Square values to get energy, then sort by descending energy\n","        sorted_users = user_similarities.map(np.square).sort_values(ascending=False)\n","\n","        # Calculate total energy\n","        total_energy = sorted_users.sum()\n","\n","        # Find the subset of users whose energy sums to the given threshold of the total energy\n","        cumulative_energy = 0\n","        selected_users = []\n","        for other_user, user_energy in sorted_users.items():\n","            cumulative_energy += user_energy\n","            selected_users.append(other_user)\n","            if cumulative_energy / total_energy >= threshold:\n","                break\n","\n","        result[user_index] = selected_users\n","\n","    return result\n","\n","# Assuming `similarities_hourly_cal` is your cosine similarity matrix for the entire dataset\n","most_corr_users_hourly_cal = most_correlated_users(similarities_hourly_cal)\n","most_corr_users_half_hourly_cal = most_correlated_users(similarities_half_hourly_cal)\n","\n","# Similarly for JPL data\n","most_corr_users_hourly_JPL = most_correlated_users(similarities_hourly_JPL)\n","most_corr_users_half_hourly_JPL = most_correlated_users(similarities_half_hourly_JPL)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":216,"status":"ok","timestamp":1700246230304,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"cAknC0g1Uw2f"},"outputs":[],"source":["#Using threshold\n","def most_correlated_users(matrix, threshold=0.85):\n","    \"\"\"\n","    For each user, find the top correlated users with correlations above 0.5.\n","\n","    :param matrix: Cosine similarity matrix.\n","    :param threshold: Minimum correlation threshold for considering a user as correlated.\n","    :return: Dictionary with keys being user IDs and values being lists of top correlated user IDs.\n","    \"\"\"\n","    result = {}\n","\n","    for user_index in matrix.index:\n","        # Subtract self-similarity value for the current user\n","        user_similarities = matrix.loc[user_index].drop(user_index)\n","\n","        # Filter users with correlation above the threshold\n","        filtered_users = user_similarities[abs(user_similarities) > threshold]\n","\n","        # Sort by descending correlation\n","        sorted_users = filtered_users.sort_values(ascending=False)\n","\n","        # Append users above the threshold to the result\n","        result[user_index] = sorted_users.index.tolist()\n","\n","    return result\n","\n","# Assuming `similarities_hourly_cal` is your cosine similarity matrix for the entire dataset\n","most_corr_users_hourly_cal = most_correlated_users(similarities_hourly_cal)\n","most_corr_users_half_hourly_cal = most_correlated_users(similarities_half_hourly_cal)\n","\n","# Similarly for JPL data\n","most_corr_users_hourly_JPL = most_correlated_users(similarities_hourly_JPL)\n","most_corr_users_half_hourly_JPL = most_correlated_users(similarities_half_hourly_JPL)"]},{"cell_type":"markdown","metadata":{"id":"QIHn62MOuwqz"},"source":["#DKDE Energy Consumption (no correlations - individual user's data **only**)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":162,"status":"ok","timestamp":1700246234287,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"_Dta-nKctzVj"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","from kde_diffusion import kde2d\n","def dkde(train_data,test_data,user_id):\n","    # Filter training and testing data for the specific user\n","    user_train_data = train_data[train_data[:, 3] == user_id]\n","    user_test_data = test_data[test_data[:, 3] == user_id]\n","\n","    # Extract columns for stay duration and energy consumption for both train and test sets\n","    X_train = user_train_data[:, 0]  # Stay duration\n","    Y_train = user_train_data[:, 4] # Energy consumption\n","\n","    X_test = user_test_data[:, 0]\n","    y_test = user_test_data[:, 4]\n","\n","    (density, grid, bandwidth) = kde2d(X_train, Y_train, n=256, limits=None)\n","\n","    def predict_y_given_x(new_x, grid, density):\n","        # Find the closest x index\n","        x_idx = np.argmin(np.abs(grid[0] - new_x))\n","\n","        # Get the y values and their corresponding densities for the given x\n","        y_values = grid[1]\n","        y_densities = density[x_idx]\n","\n","        # Find the y with the maximum density\n","        predicted_y = y_values[np.argmax(y_densities)]\n","\n","        return predicted_y\n","\n","    # Predict y values for X_test using the density estimate\n","    y_pred = [predict_y_given_x(x_val, grid, density) for x_val in X_test]\n","\n","    # Calculate user SMAPE\n","    n = len(y_test)\n","    smape_val = (1/ n) * np.sum(np.abs(y_test - y_pred) / (np.abs(y_test+y_pred)))*100\n","\n","    return smape_val,density,grid\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1339,"status":"ok","timestamp":1700246236916,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"uxP2njavuRcQ"},"outputs":[],"source":["# Test the function\n","user_ids_caltech = np.unique(np.concatenate((caltech_train[:, 3], caltech_test[:, 3])))\n","user_ids_JPL = np.unique(np.concatenate((JPL_train[:, 3], JPL_test[:, 3])))\n","\n","smape_list_caltech=[]\n","smape_list_JPL=[]\n","\n","for user_id in user_ids_caltech:\n","    smape, density, grid= dkde(caltech_train, caltech_test, user_id)\n","    smape_list_caltech.append(smape)\n","for user_id in user_ids_JPL:\n","    smape,density,grid = dkde(JPL_train, JPL_test, user_id)\n","    smape_list_JPL.append(smape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151,"status":"ok","timestamp":1700246239840,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"UeMPq9qkzqY2","outputId":"0f50d095-1936-4536-8130-def577aa8f54"},"outputs":[],"source":["#Calculate average SMAPE for each location\n","no_caltech_users=len(user_ids_caltech)\n","caltech_smape=sum(smape_list_caltech)/no_caltech_users\n","\n","no_JPL_users=len(user_ids_JPL)\n","JPL_smape=sum(smape_list_JPL)/no_JPL_users\n","\n","print(f\"Caltech SMAPE: {caltech_smape}\")\n","print(f\"JPL SMAPE: {JPL_smape}\")"]},{"cell_type":"markdown","metadata":{"id":"PIiUPuWobjtE"},"source":["#Calculate DKDE models for all users"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":896,"status":"ok","timestamp":1700246277636,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"KK43XGOHv0U9"},"outputs":[],"source":["import numpy as np\n","from kde_diffusion import kde2d\n","\n","class KDEModel:\n","    def __init__(self, grid, density):\n","        self.grid = grid\n","        self.density = density\n","\n","    def predict(self, X):\n","        predictions = [self._predict_y_given_x(x) for x in X]\n","        return predictions\n","\n","    def _predict_y_given_x(self, new_x):\n","        # Find the closest x index\n","        x_idx = np.argmin(np.abs(self.grid[0] - new_x))\n","\n","        # Get the y values and their corresponding densities for the given x\n","        y_values = self.grid[1]\n","        y_densities = self.density[x_idx]\n","\n","        # Find the y with the maximum density\n","        predicted_y = y_values[np.argmax(y_densities)]\n","\n","        return predicted_y\n","\n","def train_user_model(train_data, user_id):\n","    # Filter training data for the specific user\n","    user_train_data = train_data[train_data[:, 3] == user_id]\n","\n","    # Extract columns for stay duration and energy consumption\n","    X_train = user_train_data[:, 0]  # Stay duration\n","    Y_train = user_train_data[:, 4]  # Energy consumption\n","\n","    # Perform KDE\n","    density, grid, bandwidth = kde2d(X_train, Y_train, n=64, limits=None)\n","\n","    # Create and return a KDE model instance\n","    kde_model = KDEModel(grid, density)\n","    return kde_model\n","\n","all_user_models_caltech = {user_id: train_user_model(caltech_train, user_id) for user_id in user_ids_caltech}\n","all_user_models_JPL = {user_id: train_user_model(JPL_train, user_id) for user_id in user_ids_JPL}"]},{"cell_type":"markdown","metadata":{"id":"Jl4DFIy2MtrB"},"source":["#DKDE Energy Consumption including most correlated users"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":152,"status":"ok","timestamp":1700246278506,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"FKL74Nbubkuv"},"outputs":[],"source":["def train_and_test_user_model_with_correlation(train_data, test_data, user_id, most_corr_users, all_user_models, similarity_matrix):\n","    # Filter training and testing data for the specific user\n","    user_train_data = train_data[train_data[:, 3] == user_id]\n","    user_test_data = test_data[test_data[:, 3] == user_id]\n","\n","    X_test = user_test_data[:, 0]\n","    y_test = user_test_data[:, 4]\n","\n","    # Get the user's KDE model\n","    user_model = all_user_models[user_id]\n","\n","    # Predict y values for X_test using the KDE model\n","    y_pred = user_model.predict(X_test)\n","\n","    # Adjust the prediction based on the most correlated users\n","    if user_id in most_corr_users:\n","        correlated_users = most_corr_users[user_id]\n","        total_correlation = 1\n","\n","        for other_user_id in correlated_users:\n","            if other_user_id in all_user_models:\n","                correlation = similarity_matrix.loc[user_id, other_user_id]\n","                other_user_model = all_user_models[other_user_id]\n","\n","                # Predict using the other user's model\n","                other_user_pred = other_user_model.predict(X_test)\n","\n","                # Weight the prediction by the correlation and add to the base prediction\n","                y_pred = [y + other_y * correlation for y, other_y in zip(y_pred, other_user_pred)]\n","                total_correlation += correlation\n","\n","        if total_correlation != 0:\n","            y_pred = [y / total_correlation for y in y_pred]\n","\n","    # Calculate user SMAPE\n","    n = len(y_test)\n","    smape_val = (1/ n) * np.sum(np.abs(y_test - y_pred) / (np.abs(y_test + y_pred))) * 100\n","\n","    return smape_val, total_correlation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":211,"status":"ok","timestamp":1700246280404,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"fepqJRoPbzdq"},"outputs":[],"source":["user_ids_caltech = np.unique(np.concatenate((caltech_train[:, 3], caltech_test[:, 3])))\n","user_ids_JPL = np.unique(np.concatenate((JPL_train[:, 3], JPL_test[:, 3])))\n","\n","smape_list_caltech=[]\n","smape_list_JPL=[]\n","sum_of_correlations_list=[]\n","for user_id in user_ids_caltech:\n","    smape,sum_of_correlations = train_and_test_user_model_with_correlation(caltech_train, caltech_test, user_id, most_corr_users_half_hourly_cal,all_user_models_caltech,similarities_half_hourly_cal)\n","    smape_list_caltech.append(smape)\n","    sum_of_correlations_list.append(sum_of_correlations)\n","for user_id in user_ids_JPL:\n","    smape,sum_of_correlations = train_and_test_user_model_with_correlation(JPL_train, JPL_test, user_id, most_corr_users_half_hourly_JPL,all_user_models_JPL,similarities_half_hourly_JPL)\n","    smape_list_JPL.append(smape)\n","    sum_of_correlations_list.append(sum_of_correlations)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":130,"status":"ok","timestamp":1700246294315,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":300},"id":"cIcBop98ebYB","outputId":"6ea12ce4-25d4-4b7c-8ae1-870ed7b191b6"},"outputs":[],"source":["#Calculate average SMAPE for each location\n","no_caltech_users=len(user_ids_caltech)\n","caltech_smape=sum(smape_list_caltech)/no_caltech_users\n","\n","no_JPL_users=len(user_ids_JPL)\n","JPL_smape=sum(smape_list_JPL)/no_JPL_users\n","\n","print(f\"Caltech SMAPE: {caltech_smape}\")\n","print(f\"JPL SMAPE: {JPL_smape}\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOUuKQqjMPBsY4Z8RU41VV1","provenance":[{"file_id":"1f8WWaIx1ddgOUiup0tqeG0XD2manNeYl","timestamp":1700083718483},{"file_id":"1g84ioWe5EGTvLPBT-4Gk4H5-3iIY1hqv","timestamp":1700080513794},{"file_id":"1AQAcH3foS8kFBaI9CBrDIRW-C_qmNsYR","timestamp":1700079004583},{"file_id":"1_zSSH0LCUppl_Is9UdX79AayTAr5WjAa","timestamp":1700069210316},{"file_id":"1RehB3ik2AdRZku3yRoWVbsnv6vZDFuUw","timestamp":1700064728380},{"file_id":"19aOvXXPl1Rucdu0Z88HqTTP8RmiM_ipp","timestamp":1700022651684},{"file_id":"1cHdtNhA0ZofPXHdaPZsmHLX2gZDj3dJu","timestamp":1700006144358},{"file_id":"1M7ugd_F2UMQ796HlUfsXUl_Ucqj4nf54","timestamp":1697595791414}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}

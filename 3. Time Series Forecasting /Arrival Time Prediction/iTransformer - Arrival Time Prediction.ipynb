{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11113,"status":"ok","timestamp":1704621298143,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":-120},"id":"vhfUoHGlGLgn","outputId":"e6426cdc-40c1-4c19-b3b8-b3ab3227c2a1"},"outputs":[],"source":["!pip install iTransformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xOXgh901GVlr"},"outputs":[],"source":["import torch\n","from iTransformer import iTransformer\n"]},{"cell_type":"markdown","metadata":{"id":"6-ISMtnM2w1u"},"source":["#Load dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21191,"status":"ok","timestamp":1704621339291,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":-120},"id":"Hf3IrHmb2yLT","outputId":"15f40d5d-9e57-4d6c-c647-4124c5071fd0"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NA1JIKPN3JDq"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","# Define the file paths\n","\n","file_path3 = '/content/drive/MyDrive/SuperUROP /Data Analysis/JPL_training_data.csv'\n","file_path4  = '/content/drive/MyDrive/SuperUROP /Data Analysis/JPL_testing_data.csv'\n","# Use pandas to read the CSV files and then convert them to NumPy arrays\n","JPL_train = pd.read_csv(file_path3).values\n","JPL_test=pd.read_csv(file_path4).values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P77RMUn63L7r"},"outputs":[],"source":["#Remove row number (in 1st column)\n","JPL_train=JPL_train[:,1:]\n","JPL_test=JPL_test[:,1:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m6dPX9Yk3S1H"},"outputs":[],"source":["import math\n","\n","# Extracting the unique IDs from column 3\n","unique_ids = np.unique(JPL_train[:, 3])\n","\n","# Finding the corresponding number of unique charging parameters for each ID\n","users_charg_sessions = {uid: JPL_train[JPL_train[:, 3] == uid, -1][0] for uid in unique_ids}\n","\n","n_values=users_charg_sessions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gqeDvLxV7QD8"},"outputs":[],"source":["users_from_training = set(JPL_train[:, 3])\n","mask = np.isin(JPL_test[:, 3], list(users_from_training))\n","filtered_JPL_test = JPL_test[mask]\n","\n","users_from_testing = set(JPL_test[:, 3])\n","mask = np.isin(JPL_train[:, 3], list(users_from_testing))\n","filtered_JPL_train = JPL_train[mask]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1704621341467,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":-120},"id":"SN-oEO047U0a","outputId":"7a61d9e4-fa59-46f9-df7e-a138c8cac49c"},"outputs":[],"source":["# Converting to DataFrame\n","df_train = pd.DataFrame(filtered_JPL_train, columns=['arrival_time', 'departure_time', 'duration', 'user_id', 'energy', 'no_sessions'])\n","df_test = pd.DataFrame(filtered_JPL_test, columns=['arrival_time', 'departure_time', 'duration', 'user_id', 'energy', 'no_sessions'])\n","\n","# Sorting by start_time within each user_id\n","sorted_JPL_train = df_train.sort_values(by=['user_id', 'arrival_time'])\n","sorted_JPL_test = df_test.sort_values(by=['user_id', 'arrival_time'])\n","\n","sorted_JPL_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1704621341467,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":-120},"id":"CFbrpZBO7YZd","outputId":"638280bf-0ab8-4b70-f37e-f140cc8d8968"},"outputs":[],"source":["user_counts_train = sorted_JPL_train['user_id'].value_counts()\n","min_sessions_train=min(user_counts_train)\n","min_sessions_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yLat8lI-7dq9"},"outputs":[],"source":["# Grouping by 'user_id' and taking the last n rows for each user\n","filtered_sessions = sorted_JPL_train.groupby('user_id').apply(lambda x: x.tail(min_sessions_train))\n","\n","last_n_rows_per_user = filtered_sessions.reset_index(drop=True)\n","last_n_rows_per_user=last_n_rows_per_user[['arrival_time', 'user_id']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1OZVbndf7fh3"},"outputs":[],"source":["# Resetting the index\n","sorted_JPL_test = sorted_JPL_test.reset_index(drop=True)\n","sorted_JPL_test=sorted_JPL_test[['arrival_time', 'user_id']]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1704621341467,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":-120},"id":"JzvPjVTs7hn6","outputId":"cd1e53a2-41cf-4977-b345-8ce9b09ba789"},"outputs":[],"source":["def convert_to_hours(time_str):\n","    time_parts = time_str.split()[1].split(':') # Splitting to get only the time part\n","    hours = int(time_parts[0]) + int(time_parts[1])/60 + int(time_parts[2])/3600\n","    return round(hours, 2) # Rounding to 2 decimal places\n","\n","\n","last_n_rows_per_user['arrival_time_hours'] = last_n_rows_per_user['arrival_time'].apply(convert_to_hours)\n","last_n_rows_per_user = last_n_rows_per_user.drop(columns=['arrival_time'])\n","last_n_rows_per_user"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1704621341902,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":-120},"id":"vJiR-wT27k7x","outputId":"11729d28-6aba-45f8-9606-0f5850f7c9f7"},"outputs":[],"source":["sorted_JPL_test['arrival_time_hours'] = sorted_JPL_test['arrival_time'].apply(convert_to_hours)\n","sorted_JPL_test = sorted_JPL_test.drop(columns=['arrival_time'])\n","sorted_JPL_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":533,"status":"ok","timestamp":1704621343665,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":-120},"id":"96wH8Sv67nzf","outputId":"31c41193-9208-4455-dd2c-525b93a19948"},"outputs":[],"source":["arrival_time_per_user = last_n_rows_per_user.groupby('user_id')['arrival_time_hours'].apply(list)\n","arrival_time_per_user"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1704621346125,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":-120},"id":"nR3RFPu97reS","outputId":"11c6bfcd-da39-473c-f03c-2b3ecc8cf345"},"outputs":[],"source":["arrival_time_per_user_test = sorted_JPL_test.groupby('user_id')['arrival_time_hours'].apply(list)\n","arrival_time_per_user_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1704621347901,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":-120},"id":"YwNLfd5d9DK2","outputId":"4852cac2-4a87-4643-a549-a8d1e7dd3959"},"outputs":[],"source":["time_series = torch.tensor(arrival_time_per_user.tolist()).unsqueeze(0)\n","\n","time_series.shape, time_series.dtype"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1704621348719,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":-120},"id":"tlSHLYvk-KfS","outputId":"e9041b6d-77ca-4cdf-f2c5-432ace389381"},"outputs":[],"source":["transposed_time_series = time_series.transpose(1, 2)  # (batch, lookback len, variates)\n","\n","transposed_time_series.shape, transposed_time_series.dtype"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPWTu95M-1Dw"},"outputs":[],"source":["array_list_test = [np.array(lst) for lst in arrival_time_per_user_test]\n","\n","# Find the maximum length among the arrays\n","max_length = max(len(arr) for arr in array_list_test)\n","\n","# Pad each array to have the same length\n","padded_array_list_test = [np.pad(arr, (0,max_length - len(arr)), 'constant') for arr in array_list_test]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1704621351210,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":-120},"id":"MLB5tQchBiml","outputId":"2320f29a-c68b-44d4-ec4a-bfcd8675a5a7"},"outputs":[],"source":["padded_array_list_test"]},{"cell_type":"markdown","metadata":{"id":"qIxuTh1i-Rq3"},"source":["#Train iTransformer model"]},{"cell_type":"markdown","metadata":{"id":"k_XgzSciCiX2"},"source":["#Evaluate model"]},{"cell_type":"markdown","metadata":{"id":"oGK_k5ZQjdDW"},"source":["##Modify test dataset in the correct format"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1704621363503,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":-120},"id":"03lg_rxHCpBL","outputId":"3e376dd1-be75-4d4a-e824-ebb0d8ea8858"},"outputs":[],"source":["# Combine the arrays into a single 2D array and convert to a tensor\n","combined_array = torch.tensor(padded_array_list_test).T  # Transpose to get the shape [20, 43]\n","\n","# Reshape to [1, 20, 43]\n","test_tensor = combined_array.unsqueeze(0)\n","\n","# Verify the shape\n","print(test_tensor.shape)  # Should output torch.Size([1, 20, 43])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1704537222974,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":-120},"id":"zzev1v8doFHA","outputId":"70c1e904-370e-48d7-955d-6d40b94763f6"},"outputs":[],"source":["# Assuming predictions and ground_truth are your tensors of shape [1, 19, 43]\n","# and both are already in the same dtype, preferably float32\n","\n","# Step 1: Create a mask where the ground_truth is not zero\n","mask = test_tensor_adjusted_float != 0\n","\n","# Step 2: Apply the mask to both tensors\n","masked_predictions = predictions[mask]\n","masked_ground_truth = test_tensor_adjusted_float[mask]\n","\n","# Step 3: Compute the MSE\n","# Ensure that masked_predictions and masked_ground_truth are not empty\n","if masked_predictions.numel() > 0 and masked_ground_truth.numel() > 0:\n","    mse = torch.mean((masked_predictions - masked_ground_truth) ** 2)\n","else:\n","    mse = torch.tensor(float('nan'))  # Or handle this case as per your requirement\n","\n","print(f\"Mean Squared Error: {mse}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4687416,"status":"ok","timestamp":1704628324752,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":-120},"id":"5yBT6oJvfOsd","outputId":"d0549bb1-a184-4d99-dd6e-2d02632db4e8"},"outputs":[],"source":["import torch\n","import torch.optim as optim\n","from iTransformer import iTransformer\n","from torch.utils.data import DataLoader\n","import copy\n","import torch.nn as nn\n","import torch.nn.init as init\n","import random\n","\n","# Function to calculate SMAPE\n","def calculate_smape(predictions, ground_truth):\n","    predictions = predictions.float()\n","    ground_truth = ground_truth.float()\n","    mask = ground_truth != 0\n","    masked_predictions = predictions[mask]\n","    masked_ground_truth = ground_truth[mask]\n","    numerator = torch.abs(masked_predictions - masked_ground_truth)\n","    denominator = torch.abs(masked_predictions) + torch.abs(masked_ground_truth)\n","    smape = torch.mean(numerator / denominator)\n","    return smape.item()\n","\n","# Initialization methods\n","def xavier_init(m):\n","    if isinstance(m, nn.Linear):\n","        init.xavier_uniform_(m.weight)\n","        if m.bias is not None:\n","            init.zeros_(m.bias)\n","\n","def kaiming_init(m):\n","    if isinstance(m, nn.Linear):\n","        init.kaiming_uniform_(m.weight, nonlinearity='relu')\n","        if m.bias is not None:\n","            init.zeros_(m.bias)\n","\n","def uniform_init(m):\n","    if isinstance(m, nn.Linear):\n","        init.uniform_(m.weight, -0.1, 0.1)\n","        if m.bias is not None:\n","            init.zeros_(m.bias)\n","\n","initialization_methods = [xavier_init, kaiming_init, uniform_init]\n","\n","# Constants\n","lookback_len = 19\n","num_variates = 43\n","pred_length = 19\n","num_iterations = 200\n","\n","best_smape_error = float('inf')\n","best_model_state = None\n","best_init_method = None\n","\n","for iteration in range(num_iterations):\n","    # Randomly select an initialization method\n","    init_method = random.choice(initialization_methods)\n","\n","    # Model initialization\n","    model = iTransformer(\n","        num_variates=num_variates,\n","        lookback_len=lookback_len,\n","        dim=32,\n","        depth=4,\n","        heads=8,\n","        dim_head=32,\n","        pred_length=pred_length,\n","        num_tokens_per_variate=2,\n","    )\n","\n","    # Apply selected initialization\n","    model.apply(init_method)\n","\n","    # Loss function and optimizer\n","    loss_function = torch.nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=1000)\n","\n","    # DataLoader for training data\n","    train_loader = DataLoader(transposed_time_series, batch_size=2, shuffle=False)\n","\n","    # Training loop\n","    model.train()\n","    for epoch in range(1000):\n","        total_loss = 0\n","        for inputs in train_loader:\n","            x = inputs[:, :lookback_len, :]\n","            y = inputs[:, 1:lookback_len+1, :]\n","            optimizer.zero_grad()\n","            outputs = model(x)\n","            loss = loss_function(outputs[pred_length], y)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        scheduler.step()\n","    # Evaluation\n","    test_tensor_adjusted = transposed_time_series[:, :19, :]\n","    test_tensor_adjusted_float = test_tensor_adjusted.float()\n","    model.eval()\n","\n","    with torch.no_grad():\n","        model_output = model(test_tensor_adjusted_float)\n","        if pred_length in model_output:\n","            predictions = model_output[pred_length]\n","            smape_error = calculate_smape(predictions, test_tensor_adjusted_float)\n","            if smape_error < best_smape_error:\n","                best_smape_error = smape_error\n","                best_model_state = copy.deepcopy(model.state_dict())\n","                best_init_method = init_method.__name__\n","\n","  # Print the best initialization method and SMAPE error\n","                print(f\"Best Initialization Method: {best_init_method}\")\n","                print(f\"Best SMAPE Error(%): {best_smape_error*100}\")\n","\n","  # Optionally, save the best model state\n","  # if best_model_state is not None:\n","  #     torch.save(best_model_state, 'best_model.pth')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNnZbkZE0qb02hAdzpWhySl","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}

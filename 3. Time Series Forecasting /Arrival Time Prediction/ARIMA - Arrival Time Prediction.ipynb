{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20478,"status":"ok","timestamp":1706627848189,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"Sm1lc59VG-LC","outputId":"da716fa6-29e3-408b-923a-a6a51975b571"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1294,"status":"ok","timestamp":1706627849476,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"wf5ML6iKHBO-"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","# Define the file paths\n","file_path1 = '/content/drive/MyDrive/SuperUROP /Data Analysis/JPL_training_data.csv'\n","file_path2= '/content/drive/MyDrive/SuperUROP /Data Analysis/JPL_testing_data.csv'\n","\n","JPL_train= pd.read_csv(file_path1).values\n","JPL_test= pd.read_csv(file_path2).values\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":205,"status":"ok","timestamp":1706627851452,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"pZun_EdVHFaK"},"outputs":[],"source":["#Remove row number (in 1st column)\n","JPL_train=JPL_train[:,1:]\n","JPL_test=JPL_test[:,1:]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1706627851990,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"CaFJJMtwHGb1"},"outputs":[],"source":["import pandas as pd\n","\n","def process_dataframe(df):\n","    # Select only columns 0 and 3\n","    df = pd.DataFrame(df)\n","    selected_df = df.iloc[:, [0, 3]]\n","\n","    # Splitting the date and time in column 0\n","    df_split = selected_df[0].str.split(' ', expand=True)\n","\n","    # Renaming the columns for clarity\n","    df_split.columns = ['Date', 'Time']\n","\n","    # Including the second column from the original data\n","    processed_df = pd.concat([df_split, selected_df.iloc[:, 1]], axis=1)\n","\n","    # Rename the UserID column for clarity\n","    processed_df.rename(columns={3: 'UserID'}, inplace=True)\n","\n","    return processed_df\n","\n","# Usage example\n","JPL_train = process_dataframe(JPL_train)\n","JPL_test = process_dataframe(JPL_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":223,"status":"ok","timestamp":1706627853563,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"N1r1AA5vHKoi"},"outputs":[],"source":["def convert_time_to_decimal(time_str):\n","    # Splitting the time into hours, minutes, and seconds\n","    hours, minutes, seconds = map(int, time_str.split(':'))\n","\n","    # Converting time to decimal format\n","    decimal_hours = hours + minutes / 60 + seconds / 3600\n","\n","    return decimal_hours\n","\n","# Applying the conversion to the 'Time' column\n","JPL_train['Time'] = JPL_train['Time'].apply(convert_time_to_decimal)\n","JPL_test['Time'] = JPL_test['Time'].apply(convert_time_to_decimal)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706627854516,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"pI_PK9adHNde"},"outputs":[],"source":["# Re-importing pandas as the code execution state was reset\n","import pandas as pd\n","\n","JPL_train = pd.DataFrame(JPL_train, columns=['Date', 'Time', 'UserID'])\n","JPL_train['Date'] = pd.to_datetime(JPL_train['Date'])\n","sorted_JPL_train = JPL_train.sort_values(by=['UserID', 'Date', 'Time'])\n","\n","\n","JPL_test = pd.DataFrame(JPL_test, columns=['Date', 'Time', 'UserID'])\n","JPL_test['Date'] = pd.to_datetime(JPL_test['Date'])\n","sorted_JPL_test = JPL_test.sort_values(by=['UserID', 'Date', 'Time'])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":318,"status":"ok","timestamp":1706627855790,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"Un_GGZntHPDR"},"outputs":[],"source":["#Keep only one session (earliest) per day for each user\n","# Assuming your DataFrame is named df and is structured as shown\n","sorted_JPL_train['Date'] = pd.to_datetime(sorted_JPL_train['Date'])\n","\n","# Group by 'UserID' and 'Date', then find the index of the earliest 'Time' for each group\n","idx = sorted_JPL_train.groupby(['UserID', 'Date'])['Time'].idxmin()\n","\n","# Use these indices to filter the original DataFrame\n","sorted_JPL_train = sorted_JPL_train.loc[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706627856531,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"2YIL3b9nHbPG"},"outputs":[],"source":["#Keep only one session (earliest) per day for each user\n","# Assuming your DataFrame is named df and is structured as shown\n","sorted_JPL_test['Date'] = pd.to_datetime(sorted_JPL_test['Date'])\n","\n","# Group by 'UserID' and 'Date', then find the index of the earliest 'Time' for each group\n","idx = sorted_JPL_test.groupby(['UserID', 'Date'])['Time'].idxmin()\n","\n","# Use these indices to filter the original DataFrame\n","sorted_JPL_test = sorted_JPL_test.loc[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":178,"status":"ok","timestamp":1706627857896,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"l0pG4NANJeRJ"},"outputs":[],"source":["# Find common UserIDs\n","common_user_ids = set(sorted_JPL_train['UserID']).intersection(set(sorted_JPL_test['UserID']))\n","# # Filter both datasets to include only common UserIDs\n","sorted_JPL_train = sorted_JPL_train[sorted_JPL_train['UserID'].isin(common_user_ids)]\n","sorted_JPL_test = sorted_JPL_test[sorted_JPL_test['UserID'].isin(common_user_ids)]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1706627858398,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"UU0JzJgdbe2e"},"outputs":[],"source":["import pandas as pd\n","\n","sorted_JPL_train= pd.DataFrame(sorted_JPL_train)\n","\n","# Removing the 'Date' column and resetting index for each user\n","sorted_JPL_train = sorted_JPL_train.drop('Date', axis=1)\n","sorted_JPL_train = sorted_JPL_train.groupby('UserID').apply(lambda x: x.reset_index(drop=True)).reset_index(level=0,drop=True)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1706627859546,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"B2fysqxlcmBw"},"outputs":[],"source":["sorted_JPL_test= pd.DataFrame(sorted_JPL_test)\n","\n","# Removing the 'Date' column and resetting index for each user\n","sorted_JPL_test = sorted_JPL_test.drop('Date', axis=1)\n","sorted_JPL_test = sorted_JPL_test.groupby('UserID').apply(lambda x: x.reset_index(drop=True)).reset_index(level=0,drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1706627860495,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"GVJGz2FRcrsR","outputId":"f13d8453-e01e-448c-eedd-b0055a844d29"},"outputs":[],"source":["sorted_JPL_train"]},{"cell_type":"markdown","metadata":{"id":"H6R1TtqNIA-t"},"source":["#Create ARIMA model for each user"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1579,"status":"ok","timestamp":1706627863746,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"DzLfxFF3IpcS","outputId":"cf302c7e-7343-4cd6-f701-8a9bb611125a"},"outputs":[],"source":["import pandas as pd\n","from statsmodels.tsa.stattools import adfuller\n","\n","def find_optimal_d_for_user(df, user_id):\n","    # Filter the dataframe for the given user\n","    user_df = df[df['UserID'] == user_id]\n","\n","    # Check stationarity and find optimal d\n","    d = 0\n","    while True:\n","        adf_test = adfuller(user_df['Time'])\n","        p_value = adf_test[1]\n","        if p_value < 0.05:\n","            # The series is stationary\n","            break\n","        else:\n","            # The series is not stationary, apply differencing\n","            user_df = user_df.diff().dropna()\n","            d += 1\n","\n","    return d\n","\n","# Load the dataset\n","df = sorted_JPL_train\n","\n","# Find the unique user IDs\n","unique_users = df['UserID'].unique()\n","\n","# Dictionary to hold the optimal d value for each user\n","optimal_d_values = {}\n","\n","# Iterate over each user and find the optimal d value\n","for user in unique_users:\n","    optimal_d_values[user] = find_optimal_d_for_user(df, user)\n","\n","# Print the optimal d values for each user\n","print(optimal_d_values)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1706627865099,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"fcLbvjsce0gD","outputId":"bca067e6-9dbf-40b5-8cf6-6934fe97e8ad"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from statsmodels.tsa.stattools import acf, pacf\n","\n","def find_optimal_p_q_for_user(df, user_id, d_value, significance_level=0.05):\n","    # Filter the dataframe for the given user\n","    user_df = df[df['UserID'] == user_id]\n","\n","    # Differencing the series based on the optimal d value, if d is not 0\n","    if d_value > 0:\n","        user_df = user_df.diff(d_value).dropna()\n","\n","    # Length of the user's time series data\n","    N = len(user_df)\n","\n","    # Critical value for the given significance level\n","    critical_value = 1.96 / np.sqrt(N)\n","\n","    # Set the maximum number of lags for ACF and PACF (up to 50% of the sample size)\n","    max_lags = min(20, int(N / 2 - 1))\n","\n","    # Calculate ACF and PACF\n","    lag_acf = acf(user_df['Time'], nlags=max_lags)\n","    lag_pacf = pacf(user_df['Time'], nlags=max_lags, method='ols')\n","\n","    # Find the optimal p value (where PACF first crosses the critical value)\n","    p = next((i for i, x in enumerate(lag_pacf) if abs(x) < critical_value), None)\n","\n","    # Find the optimal q value (where ACF first crosses the critical value)\n","    q = next((i for i, x in enumerate(lag_acf) if abs(x) < critical_value), None)\n","\n","    return p, q\n","\n","# Load the dataset\n","df = sorted_JPL_train\n","\n","# Assuming you have a dictionary `optimal_d_values` from the previous step\n","optimal_pq_values = {}\n","\n","# Iterate over each user and find the optimal p and q value\n","for user in df['UserID'].unique():\n","    d_value = optimal_d_values[user]\n","    optimal_pq_values[user] = find_optimal_p_q_for_user(df, user, d_value)\n","\n","# Print the optimal p and q values for each user\n","print(optimal_pq_values)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6633,"status":"ok","timestamp":1706627873579,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"4VVL1V98f7ES","outputId":"7484b360-4a19-457f-dcdc-c1966b864fe2"},"outputs":[],"source":["import pandas as pd\n","from statsmodels.tsa.arima.model import ARIMA\n","\n","# Assuming you have two dictionaries: optimal_d_values and optimal_pq_values\n","# Also assuming you have a DataFrame df containing the time series data\n","\n","# Dictionary to store ARIMA models for each user\n","arima_models = {}\n","\n","# Iterate over each user\n","for user in df['UserID'].unique():\n","    # Retrieve the user's data\n","    user_df = df[df['UserID'] == user]\n","\n","    # Retrieve the optimal parameters for the user\n","    d = optimal_d_values[user]\n","    d=min(1,d)\n","    p, q = optimal_pq_values[user]\n","\n","    # Build and fit the ARIMA model\n","    model = ARIMA(user_df['Time'], order=(p, d, q))\n","    fitted_model = model.fit()\n","\n","    # Store the fitted model\n","    arima_models[user] = fitted_model\n","\n","# At this point, arima_models dictionary contains the fitted ARIMA model for each user\n"]},{"cell_type":"markdown","metadata":{"id":"5jsI9grWgxyh"},"source":["#ARIMA model predictions on test set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":822,"status":"ok","timestamp":1706627915918,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"6oDkYygmhAN6","outputId":"a4af7130-12e3-4c17-e1fb-2b90bf41eede"},"outputs":[],"source":["# Assuming you have a dictionary arima_models containing the fitted ARIMA models for each user\n","# Assuming test_df is your test dataset\n","\n","# Dictionary to store predictions for each user\n","arima_predictions = {}\n","\n","# Iterate over each user\n","for user in sorted_JPL_test['UserID'].unique():\n","    # Retrieve the test data for the user\n","    user_test_df = sorted_JPL_test[sorted_JPL_test['UserID'] == user]\n","\n","    # Retrieve the fitted ARIMA model for the user\n","    fitted_model = arima_models[user]\n","\n","    # Make out-of-sample predictions\n","    # The number of periods to predict is the length of the user's test data\n","    num_periods = len(user_test_df)\n","    user_predictions = fitted_model.forecast(steps=num_periods)\n","    # Calculate the maximum and minimum values of the predictions\n","    max_prediction = user_predictions.max()\n","    min_prediction = user_predictions.min()\n","\n","    # Calculate the difference between max and min predictions\n","    diff = max_prediction - min_prediction\n","    print(diff)\n","    # Store the predictions\n","    arima_predictions[user] = user_predictions\n","\n","# At this point, predictions dictionary contains the out-of-sample predictions for each user\n"]},{"cell_type":"markdown","metadata":{"id":"Af7OkKogqfOo"},"source":["#SMAPE on ARIMA model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pExgjmg7q-lI"},"outputs":[],"source":["df = pd.DataFrame(sorted_JPL_test)\n","\n","# Convert DataFrame to dictionary with UserID as key and Time values as list\n","true_values = df.groupby('UserID')['Time'].apply(list).to_dict()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tcmQgejWhyIb"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","def calculate_smape(actual, predicted):\n","    \"\"\"Calculate SMAPE between two series.\"\"\"\n","    denominator = (np.abs(actual) + np.abs(predicted))\n","    diff = np.abs(actual - predicted) / denominator\n","    diff[denominator == 0] = 0.0  # handle division by zero\n","    return 100 * np.mean(diff)\n","\n","# Dictionary to store SMAPE for each user\n","smape_values_arima = {}\n","\n","# Iterate over each user\n","for user in arima_predictions:\n","    # Retrieve the predicted values for the user and convert to a Pandas Series if not already\n","    predicted = pd.Series(arima_predictions[user])\n","\n","    # Retrieve the true values for the user and convert to a Pandas Series\n","    actual = pd.Series(true_values[user],index=predicted.index)\n","\n","    # Calculate SMAPE\n","    smape = calculate_smape(actual, predicted)\n","\n","    # Store the SMAPE value\n","    smape_values_arima[user] = smape\n","\n","# smape_values dictionary now contains the SMAPE for each user\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1705849577404,"user":{"displayName":"George Iacovides","userId":"10140267727913163690"},"user_tz":0},"id":"HjZ7nMNOlEW8","outputId":"7265163c-20cc-4e94-8204-1a4ea70e3935"},"outputs":[],"source":["mean_smape_arima = np.mean(list(smape_values_arima.values()))\n","\n","print(\"SMAPE of ARIMA model (%):\", mean_smape_arima)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOutdoetjy8/7eiVRsE4WaC","provenance":[{"file_id":"1wZC-LRsTIkuLqAro-qEIBXEx6hcJkNNy","timestamp":1705849110874}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
